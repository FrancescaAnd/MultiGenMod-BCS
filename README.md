# Multi-view Generative Models for Breast Cancer Screening

## Table of Contents
1. [About the project](#1-about-the-project)
2. [How to use](#2-how-to-use)

## 1. About the project
The aim of the following project is to develop and evaluate a **multi‑view generative model for mammography** to synthesize coherent craniocaudal (CC) and mediolateral oblique (MLO) mammogram views, ensuring cross-view consistency, preservation of lesions and potential improvement in data augmentation and downstream classification tasks.

The project explores **multi-view generative models for mammography**, with a focus on:
- Using **2-view (CC/MLO)** data from **INbreast** and **CBIS-DDSM**.  
- Training **GANs** to generate realistic mammograms (trying **diffusion models** for future improvements).  
- Ensuring **cross-view consistency** and exploring **lesion-conditioned generation**.  
- Supporting **data augmentation** and **explainability** in breast cancer screening.

| Stage                          | Model / Approach          | Input                                 | Conditioning / Details                         | Output                                           |
|--------------------------------|---------------------------|--------------------------------------|-----------------------------------------------|--------------------------------------|
| Multi-View Mammogram Generation | UNet Generator + PatchGAN Discriminator | Single-view mammogram (CC or MLO)    | GAN conditioned on radiomic features          | Synthetic additional view(s) (e.g., generate MLO from CC) |
| Radiomics-Conditioned Synthesis | UNet-based Conditional GAN | Mammogram patch + Radiomic vector    | Radiomics injected as additional input channels | Radiomics-consistent mammogram patch           |


   
### Abstract
This project presents a Computer-Aided Detection and Diagnosis (CADe/CADx) system for mammogram analysis that integrates deep learning techniques for mass detection, segmentation and classification.  The system is trained and evaluated on the INBreast dataset which is particularly suitable for this purpose due to its high-resolution images and detailed ground truth annotations. Our proposed pipeline begins with a pre-processing stage in order to improve model robustness, this includes data augmentation techniques such as contrast enhancement, noise addition and CLAHE. Successively it exploits a YOLOv8-based mass detection and instance segmentation model and a ResNet-based classifier to differentiate between benign and malignant masses. An Enhanced Super-Resolution GAN (ESRGAN) was also implemented with the goal of improving fine detail preservation, which is crucial for detection, segmentation, and classification. While ESRGAN is not currently integrated into our CADe/CADx system, future iterations may explore its use as a pre-processing step to further improve performance.

### Dataset
The dataset we are using is *INBreast*.
The INBreast dataset is a high-quality mammographic database designed for breast cancer research. 
It consists of 115 cases from 90 different patients, with a total of 410 full-field digital mammograms (FFDMs) in DICOM format.
Each image is expert-annotated with regions of interest (ROIs), which are labeled as masses, calcifications, distortions
or spiculated regions.
The dataset provides both:
- annotations related to ROIs of each image (including lesion properties such as size, intensity statistics, and contour
points in pixel and millimeter spaces), available in XML format.
- metadata (e.g., BIRADs class) in CSV format.

The high-quality annotations and comprehensive lesion diversity made the
INbreast dataset particularly suitable for our system tasks.

## 2. Experiment results

### Classification

| Metric    | Accuracy | Precision | Recall | F1 Score |
|-----------|----------|-----------|--------|----------|
| **Val (%)** | 96.20% | 92.68%    | 98.70% | 95.60%   |
| **Test (%)** | 97.84% | 94.81%   | 99.78% | 97.33%   |


### Image enhancement with ESRGAN
The following images are the high-resolution outputs generated by the ESRGAN model from low-resolution input images 

| Metric    | SSIM | PSNR |
|-----------|----------|-----------|
| **Validation set value** | 0.0.7183| 30.0781 dB |
| **Test set value** | 0.7045 | 30.0420 dB |


## 3. How to use
This project is implemented on a Linux-based operating system (Ubuntu 22.04.5 LTS, 64-bit).\
To run the code, a working Python environment is required.\
The system utilizes an NVIDIA GeForce RTX GPU, optimized for GPU acceleration with CUDA for enhanced performance.


Thus, It is recommended to create a Conda environment for this purpose.
```shell
conda create --name mammocad python=3.9
```
```shell
conda activate mammocad
```

Once you have downloaded this system from GitHub, navigate inside the `mammography_cad` directory (customizing path/to/directory/ with respect where you have located the system)
```shell
cd path/to/directory/mammography_cad
```

### Requirements
As first step, please install the dependencies needed for running the system.
```shell
pip install -r requirements.txt
```

### Data collection 
INbreast dataset is publicly avaiable at this link: https://www.kaggle.com/datasets/ramanathansp20/inbreast-dataset .
Once you have downloaded and unzipped the data, you have to add a `raw` folder and place it inside `data/` directory.\
Then, you have to fill it with the following folders/files:
- AllDICOMs
- AllXML
- INbreast.csv 

The *data* directory should have the following structure:
```graphql
    mammography_CAD
    │── data/                  # Datasets and preprocessing scripts
    │   │── raw/               
    │   │   │── AllDICOMs/            # DICOMs folder
    │   │   │   │── 20586908_6c613....dcm
    │   │   │   │── 20586934_6c613....dcm
    │   │   │    ...
    │   │   │── AllXML/               # XML folder
    │   │   │   │── 20586908.dcm
    │   │   │   │── 20586934.dcm
    │   │   │   ...
    │   │   └── INbreast.csv/         # CSV file
    │   │
    │   │── processed/         # Preprocessed data 
     ...

```

### Data preprocessing
To preprocess the dataset, go to *data/* directory and run dataset_preparation.py script. 
This step can be done running consequently the following commands
```shell
    cd data
    python dataset_preparation.py
```
   And then come back to the main directory

```shell 
    cd -
```
After the execution of this preprocessing step, the PNG processed images results to be located in `data/processed/` directory, while the JSON files are located in `data/json/` directory.

Specifically, it generates:
- the converted version of INbreast images from DICOM to PNG format (*`AllPNG`*)
- the augmented version of the dataset (augmentations: contrast adjustment, noise addition) in PNG format (*`augmentedPNG`*)
- the previous augmented version of the dataset enhanced using **CLAHE** (Contrast Limited Adaptive Histogram Equalization) (*`clahePNG`*)
- the file JSON containing a dictionary with information from INbreast.csv and from the annotations in XML format (*`dataset.json`*)
- the file JSON containing a dictionary with information from INbreast.csv and from the annotations in XML format for the augmented dataset (*`augmented.json`*)

As last step for preprocessing the data, run the following command to generate (inside `data/mass_masks` directory) the *binary masks* obtained from the annotations in the INbreast dataset (such as the contour points of the masses), 

   ```shell
      python utils/extract_masks.py
   ```

### Running the system



